====================================================================================================
ADVANCED MACHINE LEARNING CLASSIFICATION REPORT
====================================================================================================
Generated: 2025-11-19 23:26:54

====================================================================================================
1. DATASET SUMMARY
====================================================================================================
Total Samples: 98
Training Samples: 78
Test Samples: 20
Features Used: 1000
Classes: Control, IGT, T2DM

====================================================================================================
2. MODEL PERFORMANCE RANKING
====================================================================================================
                Model  Accuracy  F1-Micro  F1-Macro  F1-Weighted      MCC    Kappa  ROC-AUC  Train_Acc  Test_Acc  Overfit
  Logistic Regression      0.75      0.75  0.713553     0.741978 0.637598 0.603175 0.833333   1.000000      0.75 0.250000
          Extra Trees      0.75      0.75  0.673016     0.727619 0.646162 0.590164 0.833854   1.000000      0.75 0.250000
        Decision Tree      0.70      0.70  0.533333     0.640000 0.539968 0.508197 0.904167   1.000000      0.70 0.300000
  K-Nearest Neighbors      0.70      0.70  0.632168     0.678601 0.580887 0.508197 0.826562   0.717949      0.70 0.017949
              XGBoost      0.65      0.65  0.498834     0.598601 0.487196 0.426230 0.887500   1.000000      0.65 0.350000
Random Forest (Tuned)      0.65      0.65  0.480519     0.576623 0.482198 0.416667 0.869271   1.000000      0.65 0.350000
      Voting Ensemble      0.65      0.65  0.498834     0.598601 0.487196 0.426230 0.860417   1.000000      0.65 0.350000
             LightGBM      0.65      0.65  0.492063     0.590476 0.466673 0.426230 0.916667   1.000000      0.65 0.350000
    Stacking Ensemble      0.65      0.65  0.498834     0.598601 0.487196 0.426230 0.871875   1.000000      0.65 0.350000
          Naive Bayes      0.45      0.45  0.335664     0.402797 0.112430 0.098361 0.623437   0.782051      0.45 0.332051

====================================================================================================
3. BEST MODEL
====================================================================================================
Model: Logistic Regression
Test Accuracy: 0.7500
F1-Score (Weighted): 0.7420
Matthews Correlation: 0.6376
Cohen's Kappa: 0.6032
ROC-AUC: 0.8333

====================================================================================================
4. TOP 10 MOST IMPORTANT FEATURES
====================================================================================================
1. ENSG00000171227: 13.0074
2. ENSG00000135472: 12.2606
3. ENSG00000128590: 10.0076
4. ENSG00000172020: 9.7551
5. ENSG00000165949: 9.5026
6. ENSG00000172016: 9.2508
7. ENSG00000132793: 9.0009
8. ENSG00000136872: 8.5079
9. ENSG00000170509: 8.5061
10. ENSG00000187498: 8.2517

====================================================================================================
5. CROSS-VALIDATION RESULTS
====================================================================================================
Logistic Regression: 0.7967 ± 0.0695
Naive Bayes: 0.6433 ± 0.0962
K-Nearest Neighbors: 0.6425 ± 0.0688
Decision Tree: 0.5908 ± 0.0823
Random Forest (Tuned): 0.7092 ± 0.1428
XGBoost: 0.6817 ± 0.0997
LightGBM: 0.6675 ± 0.0692
Extra Trees: 0.6558 ± 0.0887

====================================================================================================
6. RECOMMENDATIONS
====================================================================================================
- Significant overfitting detected (>20%), reduce model complexity
- Moderate performance (<75%), consider more data or features
- Top 74 features capture 80% of importance
- Consider reducing to 74 features for efficiency

====================================================================================================