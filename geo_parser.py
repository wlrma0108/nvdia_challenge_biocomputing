import os
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')


class GEOSeriesMatrixParser:

    
    def __init__(self, filepath: str):
        """ì´ˆê¸°í™”"""
        self.filepath = filepath
        self.filename = os.path.basename(filepath)
        self.geo_id = self.filename.split('_')[0]
        
        self.metadata: Dict[str, List[str]] = {}
        self.expression_data: Optional[pd.DataFrame] = None
        self.sample_info: Optional[pd.DataFrame] = None
        self.diabetes_labels: Optional[List[str]] = None
        
        self.n_genes = 0
        self.n_samples = 0
        self.is_log_scaled = None
    
    def parse(self, verbose: bool = True) -> bool:
  
        if verbose:
            print(f"\n{'='*80}")
            print(f"ğŸ“‚ Parsing: {self.filename}")
            print(f"{'='*80}")
        
        try:
            # 1. íŒŒì¼ ì½ê¸°
            metadata_lines, data_lines = self._read_file()
            
            self._parse_metadata(metadata_lines)
            if verbose:
                self._print_metadata_summary()
            
            self._parse_expression_data(data_lines)
            if verbose:
                self._print_expression_summary()
            
            # 4. ìƒ˜í”Œ ì •ë³´ ì¶”ì¶œ
            self._extract_sample_info()
            if verbose:
                self._print_sample_summary()
            
            # 5. ë‹¹ë‡¨ ë¼ë²¨ ê°ì§€
            self._detect_diabetes_labels()
            if verbose:
                self._print_label_summary()
            
            return True
            
        except Exception as e:
            print(f"âŒ Error parsing {self.filename}: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _read_file(self) -> Tuple[List[str], List[List[str]]]:
        """íŒŒì¼ì„ ì½ì–´ì„œ ë©”íƒ€ë°ì´í„°ì™€ ë°ì´í„° ì„¹ì…˜ìœ¼ë¡œ ë¶„ë¦¬"""
        metadata_lines = []
        data_lines = []
        data_started = False
        
        with open(self.filepath, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                line = line.strip()
                
                if not line:
                    continue
                
                # ë©”íƒ€ë°ì´í„° ë¼ì¸ (! ì‹œì‘)
                if line.startswith('!'):
                    metadata_lines.append(line)
                
                # ë°ì´í„° í—¤ë” (ID_REF ì‹œì‘)
                elif line.startswith('"ID_REF"') or line.startswith('ID_REF'):
                    data_started = True
                    headers = [h.strip('"').strip() for h in line.split('\t')]
                    data_lines.append(headers)
                
                # ë°ì´í„° í–‰
                elif data_started:
                    data_lines.append(line.split('\t'))
        
        return metadata_lines, data_lines
    
    def _parse_metadata(self, lines: List[str]) -> None:
        """ë©”íƒ€ë°ì´í„° íŒŒì‹±"""
        for line in lines:
            parts = line.split('\t')
            key = parts[0].replace('!', '').strip()
            values = [v.strip('"').strip() for v in parts[1:] if v.strip()]
            
            if values:
                self.metadata[key] = values
    
    def _parse_expression_data(self, lines: List[List[str]]) -> None:
        """ë°œí˜„ ë°ì´í„° ë§¤íŠ¸ë¦­ìŠ¤ íŒŒì‹±"""
        if not lines or len(lines) < 2:
            print("âš ï¸  No expression data found")
            return
        
        headers = lines[0]
        data_rows = []
        
        # í—¤ë” ê¸¸ì´ì™€ ë§ëŠ” í–‰ë§Œ ì„ íƒ
        for row in lines[1:]:
            if len(row) == len(headers):
                data_rows.append(row)
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(data_rows, columns=headers)
        
        # ì¸ë±ìŠ¤ ì„¤ì •
        if 'ID_REF' in df.columns:
            df.set_index('ID_REF', inplace=True)
        
        # ìˆ«ìë¡œ ë³€í™˜
        for col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        self.expression_data = df
        self.n_genes = df.shape[0]
        self.n_samples = df.shape[1]
        
        # Log scale ê°ì§€
        self._detect_log_scale()
    
    def _detect_log_scale(self) -> None:
        """ë°ì´í„°ê°€ log-scaledì¸ì§€ ê°ì§€"""
        if self.expression_data is None:
            return
        
        max_val = self.expression_data.values.max()
        min_val = self.expression_data.values.min()
        
        if min_val >= 0 and max_val < 50:
            self.is_log_scaled = True
        elif max_val > 100:
            self.is_log_scaled = False
        else:
            self.is_log_scaled = None
    
    def _extract_sample_info(self) -> None:
        """ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ì¶”ì¶œ"""
        sample_data = {}
        
        # ìƒ˜í”Œ ID ê°€ì ¸ì˜¤ê¸°
        if 'Sample_geo_accession' not in self.metadata:
            print("âš ï¸  No sample IDs found")
            return
        
        sample_ids = self.metadata['Sample_geo_accession']
        sample_data['sample_id'] = sample_ids
        
        # ëª¨ë“  Sample_ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        for key, values in self.metadata.items():
            if key.startswith('Sample_') and key != 'Sample_geo_accession':
                if len(values) == len(sample_ids):
                    clean_key = key.replace('Sample_', '').lower()
                    sample_data[clean_key] = values
        
        self.sample_info = pd.DataFrame(sample_data)
    
    def _detect_diabetes_labels(self) -> None:
        """ìƒ˜í”Œ ë©”íƒ€ë°ì´í„°ì—ì„œ ë‹¹ë‡¨ ë¼ë²¨ ìë™ ê°ì§€"""
        if self.sample_info is None or len(self.sample_info) == 0:
            return
        
        labels = []
        
        # ê° ê·¸ë£¹ì˜ í‚¤ì›Œë“œ
        t2dm_keywords = ['t2dm', 't2d', 'type 2', 'type2', 'diabetic', 'diabetes', 'dep']
        igt_keywords = ['igt', 'impaired glucose tolerance', 'impaired glucose', 
                       'prediabetes', 'pre-diabetic', 'pre diabetic']
        t3c_keywords = ['t3cd', 't3c', 'type 3c', 'type3c']
        control_keywords = ['nd', 'non-diabetic', 'non diabetic', 'normal', 
                           'control', 'healthy']
        
        # ê° ìƒ˜í”Œì— ëŒ€í•´ ëª¨ë“  ì»¬ëŸ¼ ê²€ìƒ‰
        for idx, row in self.sample_info.iterrows():
            # ëª¨ë“  ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ê²€ìƒ‰
            row_text = ' '.join(str(v).lower() for v in row.values)
            
            # êµ¬ì²´ì„± ìˆœì„œë¡œ ì²´í¬
            if any(kw in row_text for kw in igt_keywords):
                labels.append('IGT')
            elif any(kw in row_text for kw in t3c_keywords):
                labels.append('T3cD')
            elif any(kw in row_text for kw in t2dm_keywords):
                labels.append('T2DM')
            elif any(kw in row_text for kw in control_keywords):
                labels.append('Control')
            else:
                labels.append('Unknown')
        
        self.diabetes_labels = labels
        self.sample_info['diabetes_label'] = labels
    
    def _print_metadata_summary(self) -> None:
        """ë©”íƒ€ë°ì´í„° ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“‹ METADATA:")
        
        if 'Series_title' in self.metadata:
            title = self.metadata['Series_title'][0]
            print(f"   Title: {title[:70]}...")
        
        if 'Series_geo_accession' in self.metadata:
            print(f"   GEO ID: {self.metadata['Series_geo_accession'][0]}")
        
        if 'Series_platform_id' in self.metadata:
            print(f"   Platform: {self.metadata['Series_platform_id'][0]}")
    
    def _print_expression_summary(self) -> None:
        """ë°œí˜„ ë°ì´í„° ìš”ì•½ ì¶œë ¥"""
        if self.expression_data is None:
            return
        
        print(f"\nğŸ“Š EXPRESSION MATRIX:")
        print(f"   Shape: {self.n_genes:,} genes Ã— {self.n_samples} samples")
        print(f"   Mean: {self.expression_data.values.mean():.3f}")
        print(f"   Range: [{self.expression_data.values.min():.3f}, "
              f"{self.expression_data.values.max():.3f}]")
        
        # ê²°ì¸¡ì¹˜
        missing = self.expression_data.isnull().sum().sum()
        total = self.expression_data.size
        print(f"   Missing: {missing:,} ({100*missing/total:.2f}%)")
        
        # 0 ê°’
        zeros = (self.expression_data == 0).sum().sum()
        print(f"   Zeros: {zeros:,} ({100*zeros/total:.2f}%)")
        
        # Log scale
        if self.is_log_scaled is True:
            print(f"   Scale: âœ“ LOG-SCALED")
        elif self.is_log_scaled is False:
            print(f"   Scale: LINEAR")
        else:
            print(f"   Scale: UNCERTAIN")
    
    def _print_sample_summary(self) -> None:
        """ìƒ˜í”Œ ì •ë³´ ìš”ì•½ ì¶œë ¥"""
        if self.sample_info is None:
            return
        
        print(f"\nğŸ‘¥ SAMPLES: {len(self.sample_info)}")
        print(f"   Metadata fields: {len(self.sample_info.columns)}")
    
    def _print_label_summary(self) -> None:
        """ë¼ë²¨ ê°ì§€ ê²°ê³¼ ì¶œë ¥"""
        if self.diabetes_labels is None:
            return
        
        print(f"\nğŸ¯ DIABETES LABELS:")
        label_counts = pd.Series(self.diabetes_labels).value_counts()
        
        for label, count in label_counts.items():
            if label != 'Unknown':
                print(f"   âœ“ {label}: {count} samples")
        
        if 'Unknown' in label_counts:
            print(f"   âš ï¸  Unknown: {label_counts['Unknown']} samples")
    
    def get_expression_matrix(self) -> pd.DataFrame:
        """ë°œí˜„ ë§¤íŠ¸ë¦­ìŠ¤ ë°˜í™˜"""
        return self.expression_data
    
    def get_sample_metadata(self) -> pd.DataFrame:
        """ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° ë°˜í™˜"""
        return self.sample_info
    
    def get_labels(self) -> List[str]:
        """ë‹¹ë‡¨ ë¼ë²¨ ë°˜í™˜"""
        return self.diabetes_labels
    
    def save_to_csv(self, output_dir: str = '.') -> None:
        """
        íŒŒì‹±ëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # ë°œí˜„ ë°ì´í„° ì €ì¥ (ì²˜ìŒ 1000ê°œ ìœ ì „ìë§Œ)
        if self.expression_data is not None:
            expr_file = os.path.join(output_dir, f'{self.geo_id}_expression.csv')
            self.expression_data.head(1000).to_csv(expr_file)
            print(f"ğŸ’¾ Saved: {expr_file}")
        
        # ìƒ˜í”Œ ë©”íƒ€ë°ì´í„° ì €ì¥
        if self.sample_info is not None:
            meta_file = os.path.join(output_dir, f'{self.geo_id}_metadata.csv')
            self.sample_info.to_csv(meta_file, index=False)
            print(f"ğŸ’¾ Saved: {meta_file}")


def parse_all_geo_files(input_dir: str, output_dir: str = './parsed_data') -> Dict[str, GEOSeriesMatrixParser]:
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  GEO series matrix íŒŒì¼ íŒŒì‹±
    
    Args:
        input_dir: GEO íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬
        output_dir: íŒŒì‹±ëœ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬
        
    Returns:
        GEO IDë¥¼ í‚¤ë¡œ í•˜ëŠ” íŒŒì„œ ë”•ì…”ë„ˆë¦¬
    """
    print("\n" + "="*80)
    print("ğŸ§¬ GEO SERIES MATRIX BATCH PARSER")
    print("="*80)
    
    # Series matrix íŒŒì¼ ì°¾ê¸°
    files = [f for f in os.listdir(input_dir) if f.endswith('_series_matrix.txt')]
    
    if not files:
        print(f"âŒ No series matrix files found in {input_dir}")
        return {}
    
    print(f"\nğŸ“ Found {len(files)} files:")
    for f in files:
        print(f"   â€¢ {f}")
    
    # ê° íŒŒì¼ íŒŒì‹±
    parsers = {}
    for filename in sorted(files):
        filepath = os.path.join(input_dir, filename)
        parser = GEOSeriesMatrixParser(filepath)
        
        if parser.parse(verbose=True):
            parser.save_to_csv(output_dir)
            parsers[parser.geo_id] = parser
    
    # ìš”ì•½ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š PARSING SUMMARY")
    print("="*80)
    
    summary_data = []
    for geo_id, parser in parsers.items():
        if parser.expression_data is not None:
            summary_data.append({
                'GEO_ID': geo_id,
                'Genes': parser.n_genes,
                'Samples': parser.n_samples,
                'Control': parser.diabetes_labels.count('Control') if parser.diabetes_labels else 0,
                'IGT': parser.diabetes_labels.count('IGT') if parser.diabetes_labels else 0,
                'T2DM': parser.diabetes_labels.count('T2DM') if parser.diabetes_labels else 0,
                'T3cD': parser.diabetes_labels.count('T3cD') if parser.diabetes_labels else 0,
            })
    
    if summary_data:
        summary_df = pd.DataFrame(summary_data)
        print(f"\n{summary_df.to_string(index=False)}")
        
        # ìš”ì•½ ì €ì¥
        summary_file = os.path.join(output_dir, 'parsing_summary.csv')
        summary_df.to_csv(summary_file, index=False)
        print(f"\nğŸ’¾ Summary saved: {summary_file}")
    
    print("\n" + "="*80)
    print("âœ… ALL PARSING COMPLETE!")
    print("="*80)
    
    return parsers


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == '__main__':
    # ëª¨ë“  íŒŒì¼ íŒŒì‹±
    parsers = parse_all_geo_files(
        input_dir='data',
        output_dir='outputdata'
    )
    
    # ê°œë³„ ë°ì´í„°ì…‹ ì ‘ê·¼
    if 'GSE164416' in parsers:
        gse164416 = parsers['GSE164416']
        expr = gse164416.get_expression_matrix()
        metadata = gse164416.get_sample_metadata()
        labels = gse164416.get_labels()
        
        print(f"\nğŸ¯ GSE164416 loaded:")
        print(f"  Expression shape: {expr.shape}")
        print(f"  Label distribution:")
        print(f"    {pd.Series(labels).value_counts().to_dict()}")