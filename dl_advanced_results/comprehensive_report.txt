====================================================================================================
ADVANCED DEEP LEARNING CLASSIFICATION REPORT
====================================================================================================
Generated: 2025-11-20 00:15:43
Device: cpu

====================================================================================================
1. DATASET SUMMARY
====================================================================================================
Total Samples: 98
Training Samples: 62
Validation Samples: 16
Test Samples: 20
Features: 5000
Classes: Control, IGT, T2DM

====================================================================================================
2. MODEL PERFORMANCE
====================================================================================================
       Model  Accuracy  F1-Macro  F1-Weighted  ROC-AUC
 WideAndDeep      0.65  0.580065     0.646078 0.834375
    Ensemble      0.55  0.000000     0.552381 0.000000
AttentionMLP      0.50  0.415655     0.498785 0.787500
  DeepResNet      0.45  0.343434     0.412121 0.782292

====================================================================================================
3. BEST MODEL
====================================================================================================
Model: WideAndDeep
Accuracy: 0.6500
F1-Score (Weighted): 0.6461
ROC-AUC: 0.8344

====================================================================================================
4. TRAINING INSIGHTS
====================================================================================================

DeepResNet:
  Best Epoch: 9
  Best Val Acc: 0.7500
  Final LR: 0.000914

AttentionMLP:
  Best Epoch: 15
  Best Val Acc: 0.7500
  Final LR: 0.000885

WideAndDeep:
  Best Epoch: 6
  Best Val Acc: 0.8125
  Final LR: 0.000926

====================================================================================================
5. RECOMMENDATIONS
====================================================================================================
- Consider more data or architecture tuning (<75%)
- Ensemble prediction combines multiple models for robustness
- Monitor overfitting through training curves
- Consider data augmentation for improvement

====================================================================================================